{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the neccessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from PIL import Image \n",
    "# import os\n",
    "# from PIL import Image\n",
    "# import os.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.16.1-cp39-cp39-macosx_10_15_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Using cached h5py-3.11.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.3.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting packaging (from tensorflow)\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Using cached setuptools-70.0.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting six>=1.12.0 (from tensorflow)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.64.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Using cached keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.0-cp39-cp39-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Using cached optree-0.11.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (45 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->keras>=3.0.0->tensorflow)\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Using cached zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.16.1-cp39-cp39-macosx_10_15_x86_64.whl (259.5 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.64.1-cp39-cp39-macosx_10_9_universal2.whl (10.4 MB)\n",
      "Using cached h5py-3.11.0-cp39-cp39-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Using cached keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl (26.5 MB)\n",
      "Using cached ml_dtypes-0.3.2-cp39-cp39-macosx_10_9_universal2.whl (389 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached setuptools-70.0.0-py3-none-any.whl (863 kB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.37.0-cp39-cp39-macosx_10_14_x86_64.whl (2.5 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached wrapt-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl (37 kB)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp39-cp39-macosx_10_9_x86_64.whl (122 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.11.0-cp39-cp39-macosx_10_9_x86_64.whl (295 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_x86_64.whl (14 kB)\n",
      "Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, zipp, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, six, setuptools, pygments, protobuf, packaging, numpy, mdurl, MarkupSafe, idna, grpcio, gast, charset-normalizer, certifi, absl-py, werkzeug, requests, optree, opt-einsum, ml-dtypes, markdown-it-py, importlib-metadata, h5py, google-pasta, astunparse, rich, markdown, tensorboard, keras, tensorflow\n",
      "  Attempting uninstall: namex\n",
      "    Found existing installation: namex 0.0.8\n",
      "    Uninstalling namex-0.0.8:\n",
      "      Successfully uninstalled namex-0.0.8\n",
      "  Attempting uninstall: libclang\n",
      "    Found existing installation: libclang 18.1.1\n",
      "    Uninstalling libclang-18.1.1:\n",
      "      Successfully uninstalled libclang-18.1.1\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 24.3.25\n",
      "    Uninstalling flatbuffers-24.3.25:\n",
      "      Successfully uninstalled flatbuffers-24.3.25\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.19.2\n",
      "    Uninstalling zipp-3.19.2:\n",
      "      Successfully uninstalled zipp-3.19.2\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.16.0\n",
      "    Uninstalling wrapt-1.16.0:\n",
      "      Successfully uninstalled wrapt-1.16.0\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.43.0\n",
      "    Uninstalling wheel-0.43.0:\n",
      "      Successfully uninstalled wheel-0.43.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.7\n",
      "    Uninstalling urllib3-1.26.7:\n",
      "      Successfully uninstalled urllib3-1.26.7\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 2.4.0\n",
      "    Uninstalling termcolor-2.4.0:\n",
      "      Successfully uninstalled termcolor-2.4.0\n",
      "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
      "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.0\n",
      "    Uninstalling tensorflow-io-gcs-filesystem-0.37.0:\n",
      "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 70.0.0\n",
      "    Uninstalling setuptools-70.0.0:\n",
      "      Successfully uninstalled setuptools-70.0.0\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.18.0\n",
      "    Uninstalling Pygments-2.18.0:\n",
      "      Successfully uninstalled Pygments-2.18.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: mdurl\n",
      "    Found existing installation: mdurl 0.1.2\n",
      "    Uninstalling mdurl-0.1.2:\n",
      "      Successfully uninstalled mdurl-0.1.2\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.5\n",
      "    Uninstalling MarkupSafe-2.1.5:\n",
      "      Successfully uninstalled MarkupSafe-2.1.5\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.64.1\n",
      "    Uninstalling grpcio-1.64.1:\n",
      "      Successfully uninstalled grpcio-1.64.1\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.4\n",
      "    Uninstalling gast-0.5.4:\n",
      "      Successfully uninstalled gast-0.5.4\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.6.2\n",
      "    Uninstalling certifi-2024.6.2:\n",
      "      Successfully uninstalled certifi-2024.6.2\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.9.0\n",
      "    Uninstalling absl-py-0.9.0:\n",
      "      Successfully uninstalled absl-py-0.9.0\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 3.0.3\n",
      "    Uninstalling Werkzeug-3.0.3:\n",
      "      Successfully uninstalled Werkzeug-3.0.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: optree\n",
      "    Found existing installation: optree 0.11.0\n",
      "    Uninstalling optree-0.11.0:\n",
      "      Successfully uninstalled optree-0.11.0\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.3.2\n",
      "    Uninstalling ml-dtypes-0.3.2:\n",
      "      Successfully uninstalled ml-dtypes-0.3.2\n",
      "  Attempting uninstall: markdown-it-py\n",
      "    Found existing installation: markdown-it-py 3.0.0\n",
      "    Uninstalling markdown-it-py-3.0.0:\n",
      "      Successfully uninstalled markdown-it-py-3.0.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 7.1.0\n",
      "    Uninstalling importlib_metadata-7.1.0:\n",
      "      Successfully uninstalled importlib_metadata-7.1.0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.11.0\n",
      "    Uninstalling h5py-3.11.0:\n",
      "      Successfully uninstalled h5py-3.11.0\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: astunparse\n",
      "    Found existing installation: astunparse 1.6.3\n",
      "    Uninstalling astunparse-1.6.3:\n",
      "      Successfully uninstalled astunparse-1.6.3\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.7.1\n",
      "    Uninstalling rich-13.7.1:\n",
      "      Successfully uninstalled rich-13.7.1\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.6\n",
      "    Uninstalling Markdown-3.6:\n",
      "      Successfully uninstalled Markdown-3.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.3.3\n",
      "    Uninstalling keras-3.3.3:\n",
      "      Successfully uninstalled keras-3.3.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.1\n",
      "    Uninstalling tensorflow-2.16.1:\n",
      "      Successfully uninstalled tensorflow-2.16.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-auth 2.18.0 requires urllib3<2.0, but you have urllib3 2.2.1 which is incompatible.\n",
      "mpcontribs-client 4.4.7 requires jsonschema<4.0, but you have jsonschema 4.19.2 which is incompatible.\n",
      "roboflow 1.0.8 requires certifi==2022.12.7, but you have certifi 2024.6.2 which is incompatible.\n",
      "roboflow 1.0.8 requires idna==2.10, but you have idna 3.7 which is incompatible.\n",
      "sentry-sdk 1.23.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\n",
      "tensorflow-metadata 1.13.1 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.6.2 charset-normalizer-3.3.2 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.64.1 h5py-3.11.0 idna-3.7 importlib-metadata-7.1.0 keras-3.3.3 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 numpy-1.26.4 opt-einsum-3.3.0 optree-0.11.0 packaging-24.1 protobuf-4.25.3 pygments-2.18.0 requests-2.32.3 rich-13.7.1 setuptools-70.0.0 six-1.16.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.0 termcolor-2.4.0 typing-extensions-4.12.2 urllib3-2.2.1 werkzeug-3.0.3 wheel-0.43.0 wrapt-1.16.0 zipp-3.19.2\n"
     ]
    }
   ],
   "source": [
    "#force reinstall of tensorflow\n",
    "!pip install --upgrade --force-reinstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "#!pip install ultralytics==8.0.28 #uncomment if you need to install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks() \n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "from IPython.display import display, Image\n",
    "#change the current working directory to whatever folder you have the weights stored in \n",
    "Model_dir  = \"/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/segmentation_Test/datasets/Multi-Melt-Pool-Segmentation-3\"\n",
    "#change the image directory to the location of the images you want to segment \n",
    "#make the image directory as \"/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/melt_track/Width_Model_Final/test/images\"\n",
    "img_dir = \"/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/316_mp_width/Ajay/1\"\n",
    "img_dir = os.path.normpath(img_dir)\n",
    "Calibr_Ratio = 0.003915330201 #mm/pixel --> current width for calibrator is 0.73mm-->equivalent to 173 pixels\n",
    "os.chdir(Model_dir)\n",
    "HOME = os.getcwd()\n",
    "HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is currently no official GPU support for MacOS.\n",
    "!pip install tensorflow\n",
    "# Verify the installation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the wrking directory for mac to /Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/316 mp width/20240114_1\n",
    "os.chdir('/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/316_mp_width/20240114_1')\n",
    "wrking_dir = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Change the following working directories to where you want cropped images to come from and be saved\n",
    "os.chdir('/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/316 mp width/Cropped 316SS Images')\n",
    "SOURCE_DIRECTORY = \"/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/316 mp width/old_mp_data\"\n",
    "TARGET_DIRECTORY = \"/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/316 mp width/Cropped 316SS Images\"\n",
    "directory_list = os.listdir(SOURCE_DIRECTORY)\n",
    "\n",
    "def crop():\n",
    "    for source_file in directory_list:\n",
    "        source_path = os.path.join(SOURCE_DIRECTORY, source_file) \n",
    "        if os.path.isfile(source_path):\n",
    "            raw_image = Image.open(source_path)\n",
    "            file_name = os.path.basename(source_path)\n",
    "            file_name, extension = os.path.splitext(file_name)\n",
    "\n",
    "            image_cropped_top = raw_image.crop((400, 0, 1000, 700))\n",
    "            image_cropped_top.save(file_name+'.bmp', \"BMP\", quality=100)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    crop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Segmentation Model for Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/316_mp_width\n"
     ]
    }
   ],
   "source": [
    "#change the current working directory to /Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/segmentation_Test\n",
    "os.chdir(\"/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/316_mp_width\")\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks() \n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {HOME}/datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "!pip install roboflow --quiet\n",
    "\n",
    "#to get this information, go to the roboflow website and then project, versions, export, show download code\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"vsGAwXgF6Lwda3uRtxld\")\n",
    "project = rf.workspace(\"university-of-toronto-0x7c6\").project(\"multi-melt-pool-segmentation\")\n",
    "dataset = project.version(3).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "'/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/segmentation_Test/datasets/Multi-Melt-Pool-Segmentation-2/valid/images'\n",
    "!yolo task=segment mode=train model=yolov8m-seg.pt data={dataset.location}/data.yaml epochs=10 batch=32 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {HOME}/runs/segment/train6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=f'{HOME}/runs/segment/train6/confusion_matrix.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=f'{HOME}/runs/segment/train6/results.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=segment mode=val model={HOME}/runs/segment/train6/weights/best.pt data={dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=segment mode=predict model={HOME}/runs/segment/train6/weights/best.pt conf=0.25 source=/Users/ajaytalbot/Library/CloudStorage/OneDrive-UniversityofToronto/Project_Research/Printability/segmentation_Test/datasets/Multi-Melt-Pool-Segmentation-3/test/images save=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=segment mode=export format=torchscript model={HOME}/runs/segment/train6/weights/best.pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
